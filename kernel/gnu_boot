/* Constants */
.equ KERNEL_VIRTUAL_ADDR, 0xFFFFFFFF80000000
.equ EFER_MSR, 0xC0000080


/* GDT FLAGS AND ACCESS BITS */
.equ PRESENT,         0b10000000
.equ NOT_SYS,         0b00010000
.equ EXEC,            0b00001000
.equ DC,              0b00000100
.equ RW,              0b00000010
.equ ACCESSED,        0b00000001

.equ GRAN_4K,         0b10000000
.equ SZ_32,           0b01000000
.equ LONG_MODE,       0b00100000

.equ HIGH_FLAG,       0b00001111

.equ ACCESS_FLAGS_CODE, (PRESENT | NOT_SYS | EXEC | RW)
.equ HIGH_FLAGS_CODE, (GRAN_4K | LONG_MODE | HIGH_FLAG)
.equ ACCESS_FLAGS_DATA, (PRESENT | NOT_SYS | RW)                  
.equ HIGH_FLAGS_DATA, (GRAN_4K | SZ_32 | HIGH_FLAG)     

/* Declare constants for the multiboot header. */
.set ALIGN,    1<<0             /* align loaded modules on page boundaries */
.set MEMINFO,  1<<1             /* provide memory map */
.set FLAGS,    ALIGN | MEMINFO  /* this is the Multiboot 'flag' field */
.set MAGIC,    0x1BADB002       /* 'magic number' lets bootloader find the header */
.set CHECKSUM, -(MAGIC + FLAGS) /* checksum of above, to prove we are multiboot */


/* 
Declare a multiboot header that marks the program as a kernel. These are magic
values that are documented in the multiboot standard. The bootloader will
search for this signature in the first 8 KiB of the kernel file, aligned at a
32-bit boundary. The signature is in its own section so the header can be
forced to be within the first 8 KiB of the kernel file.
*/
.section .multiboot
.align 4
.long MAGIC
.long FLAGS
.long CHECKSUM


/*
The multiboot standard does not define the value of the stack pointer register
(esp) and it is up to the kernel to provide a stack. This allocates room for a
small stack by creating a symbol at the bottom of it, then allocating 16384
bytes for it, and finally creating a symbol at the top. The stack grows
downwards on x86. The stack is in its own section so it can be marked nobits,
which means the kernel file is smaller because it does not contain an
uninitialized stack. The stack on x86 must be 16-byte aligned according to the
System V ABI standard and de-facto extensions. The compiler will assume the
stack is properly aligned and failure to align the stack will result in
undefined behavior.
*/
.section .bss
.align 16
stack_bottom:
.skip 16384 # 16 KiB
stack_top:


.section .data
.align 16
GDT:
GDT_Null: 
        .quad 0
GDT_Code: 
        .long 0xFFFF                                   # Limit & Base (low, bits 0-15)
        .byte 0                                        # Base (mid, bits 16-23)
        .byte ACCESS_FLAGS_CODE                        # Access
        .byte HIGH_FLAGS_CODE                          # Flags & Limit (high, bits 16-19)
        .byte 0                                        # Base (high, bits 24-31)
GDT_Data: 
        .long 0xFFFF                                   # Limit & Base (low, bits 0-15)
        .byte 0                                        # Base (mid, bits 16-23)
        .byte ACCESS_FLAGS_DATA                        # Access
        .byte HIGH_FLAGS_DATA                          # Flags & Limit (high, bits 16-19)
        .byte 0                                        # Base (high, bits 24-31)
GDT_TSS: 
        .long 0x00000068
        .long 0x00CF8900
GDT_Pointer:
        .word GDT_END - GDT - 1                              # size of gdt - 1
        .quad GDT                                      # Base address of gdt
GDT_END:


.section .text
.code32


/*
    We put our utility functions that can be called here
*/

detect_cpuid:
    # Check if CPUID is supported by attempting to flip the ID bit (bit 21) in
    # the FLAGS register. If we can flip it, CPUID is available.
 
    # Copy FLAGS in to EAX via stack
    pushf
    pop %eax
 
    # Copy to ECX as well for comparing later on
    mov %eax, %ecx
 
    # Flip the ID bit
    xor $1 << 21, %eax 
 
    # Copy EAX to FLAGS via the stack
    push %eax
    popf
 
    # Copy FLAGS back to EAX (with the flipped bit if CPUID is supported)
    pushf
    pop %eax
 
    # Restore FLAGS from the old version stored in ECX (i.e. flipping the ID bit
    # back if it was ever flipped).
    push %ecx
    popf
 
    # Compare EAX and ECX. If they are equal then that means the bit wasn't
    # flipped, and CPUID isn't supported.
    xor %ecx, %eax 
    jz cpuid_unavailable
    ret





/*
    We store our error detours here

    We will add error messages here eventually
*/

long_mode_unavailable:
    jmp error

cpuid_unavailable:
    jmp error




/*
The linker script specifies _start as the entry point to the kernel and the
bootloader will jump to this position once the kernel has been loaded. It
doesn't make sense to return from this function as the bootloader is gone.
*/


.global _start
.type _start, @function
_start:

/*
	The bootloader has loaded us into 32-bit protected mode on a x86
	machine. Interrupts are disabled. Paging is disabled. The processor
	state is as defined in the multiboot standard. The kernel has full
	control of the CPU. The kernel can only make use of hardware features
	and any code it provides as part of itself. There's no printf
	function, unless the kernel provides its own <stdio.h> header and a
	printf implementation. There are no security restrictions, no
	safeguards, no debugging mechanisms, only what the kernel provides
	itself. It has absolute and complete power over the
	machine.
	*/

	/*
	To set up a stack, we set the esp register to point to the top of the
	stack (as it grows downwards on x86 systems). This is necessarily done
	in assembly as languages such as C cannot function without a stack.
	*/
	mov $stack_top, %esp

	/*
	This is a good place to initialize crucial processor state before the
	high-level kernel is entered. It's best to minimize the early
	environment where crucial features are offline. Note that the
	processor is not fully initialized yet: Features such as floating
	point instructions and instruction set extensions are not initialized
	yet. The GDT should be loaded here. Paging should be enabled here.
	C++ features such as global constructors and exceptions will require
	runtime support to work as well.
	*/

check_cpuid_available:
    # this function will not return and go to error if cpuid is not supported by the processor
    call detect_cpuid 



check_longmode_available:
    # We first check if the extended functions are available, we need these to check for long mode
    # if there is no extended functions, there is no long mode
    movl $0x80000000, %eax      # Set the A-register to 0x80000000.
    cpuid                       # CPU identification.
    cmpl $0x80000001, %eax      # Compare the A-register with 0x80000001.
    jb long_mode_unavailable

    movl $0x80000001, %eax 
    cpuid

    # Check the 29th bit (bit 29) in the EDX register
    testl $1 << 29, %edx 
    jnz long_mode_available
    # error if not available
    jmp long_mode_unavailable 


long_mode_available:


disable_paging:
    mov %cr0, %eax
    # Clear the PG-bit, which is bit 31.
    andl $0b01111111111111111111111111111111, %eax
	mov %eax, %cr0

# this sequence clears the first page so we can set up the PML4T
clear_first_page:
    movl $0x1000, %edi   # set up our PML4T at 0x1000
    mov %edi, %cr3      # CR3 holds the PML4T address
    xor %eax, %eax      # set bytes = 0
clp_loop:
    mov %eax, (%edi)
    inc %edi
    inc %ecx
    cmp $4096, %ecx
    jne clp_loop
    mov %cr3, %edi      # set edi back to 0x1000

# Here we begin to set up direct mapped paging
# PML4T --> 0x1000
# PDPT  --> 0x2000
# PDT   --> 0x3000
# PT    --> 0x4000
set_up_dm_paging:
    mov $0x2000, %eax
    shl $12, %eax
    or 0b11, %eax
    movl %eax, (%edi)
    add $0x1000, %edi
    xor %eax, %eax
    mov $0x3000, %eax
    shl $12, %eax
    or 0b11, %eax
    movl %eax, (%edi)
    add $0x1000, %edi
    xor %eax, %eax
    mov $0x4000, %eax
    shl $12, %eax
    or 0b11, %eax
    movl %eax, (%edi)
    xor %eax, %eax
    #movl $0x03, %ebx
    
    xor %ebx, %ebx
    movl $512, %ecx
    xor %edx, %edx

# this loop identity maps the first 2mb of memory, we may need to do more later
dm_pages:
    cmp $0, %ecx
    je pages_identity_mapped_success
    or 0b11, %ebx
    movl %ebx, (%edi)
    xor %ebx, %ebx
    add $0x1000, %edx
    mov %edx, %ebx
    shl $12, %ebx
    add $0x8, %edi
    dec %ecx
    jmp dm_pages

pages_identity_mapped_success:

enable_pae:
    mov %cr4, %eax
    or $1 << 5, %eax        # we set the PAE-bit, which is bit 6
    mov %eax, %cr4
    mov $EFER_MSR, %ecx
    rdmsr
    or $1 << 8, %eax        # result of rdmsr is in eax, and we want to set the long-mode(LM) bit which is bit 8
    wrmsr                   # wrmsr writes eax to the msr register selected by ecx

reenable_paging:
    mov %cr0, %eax
    or $1 << 31, %eax
    mov %eax, %cr0

test:
    jmp test

load_lm_gdt:
    lgdt [GDT_Pointer]

.code64
    movw $0x8, %ax      # Assuming your code segment selector is 0x8 (adjust as necessary)
    movw %ax, %cs       # Load the segment selector into the CS register

    # Load the address into a register
    movq $enter_long_mode, %rax    # Assuming 'addr' is the address you want to jump to

    # Perform the far jump
    ljmp *(%rax)        # Far jump to the address using CS segment selector

# henceforth we are in 64bit mode


    /*
	Enter the high-level kernel. The ABI requires the stack is 16-byte
	aligned at the time of the call instruction (which afterwards pushes
	the return pointer of size 4 bytes). The stack was originally 16-byte
	aligned above and we've pushed a multiple of 16 bytes to the
	stack since (pushed 0 bytes so far), so the alignment has thus been
	preserved and the call is well defined.
	*/
enter_long_mode:

    jmp enter_long_mode
	call kernel_main











	/*
	If the system has nothing more to do, put the computer into an
	infinite loop. To do that:
	1) Disable interrupts with cli (clear interrupt enable in eflags).
	   They are already disabled by the bootloader, so this is not needed.
	   Mind that you might later enable interrupts and return from
	   kernel_main (which is sort of nonsensical to do).
	2) Wait for the next interrupt to arrive with hlt (halt instruction).
	   Since they are disabled, this will lock up the computer.
	3) Jump to the hlt instruction if it ever wakes up due to a
	   non-maskable interrupt occurring or due to system management mode.
	*/

error:
    movl $0x06690748,0xb8000
	cli
1:	hlt
	jmp 1b

/*
Set the size of the _start symbol to the current location '.' minus its start.
This is useful when debugging or when you implement call tracing.
*/
.size _start, . - _start
